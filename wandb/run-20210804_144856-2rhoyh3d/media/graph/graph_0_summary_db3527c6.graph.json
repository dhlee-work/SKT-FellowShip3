{"format": "torch", "nodes": [{"name": "mdl", "id": 140399569548768, "class_name": "Bridge(\n  (encoder_embeddings): TransformerHiddens(\n    (trans_parameters): BertModel(\n      (embeddings): BertEmbeddings(\n        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (token_type_embeddings): Embedding(2, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): BertEncoder(\n        (layer): ModuleList(\n          (0): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (1): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (2): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (3): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (4): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (5): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (6): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (7): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (8): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (9): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (10): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (11): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (pooler): BertPooler(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (activation): Tanh()\n      )\n    )\n    (dropout): Dropout(p=0.0, inplace=False)\n  )\n  (decoder_embeddings): Embedding(\n    (embeddings): Embedding(99, 400)\n    (dropout): Dropout(p=0.3, inplace=False)\n  )\n  (encoder): SchemaAwareTransformerEncoder(\n    (bilstm_encoder): RNNEncoder(\n      (rnn): LSTMWithPacking(\n        (rnn): WeightDropoutLSTM(\n          (rnn): LSTM(768, 200, batch_first=True, bidirectional=True)\n        )\n      )\n    )\n    (text_encoder): RNNEncoder(\n      (rnn): LSTMWithPacking(\n        (rnn): WeightDropoutLSTM(\n          (rnn): LSTM(400, 200, batch_first=True, bidirectional=True)\n        )\n      )\n    )\n    (schema_encoder): SchemaEncoder(\n      (primary_key_embeddings): Embedding(\n        (embeddings): Embedding(2, 400)\n        (dropout): Dropout(p=0.3, inplace=False)\n      )\n      (foreign_key_embeddings): Embedding(\n        (embeddings): Embedding(2, 400)\n        (dropout): Dropout(p=0.3, inplace=False)\n      )\n      (field_type_embeddings): Embedding(\n        (embeddings): Embedding(6, 400)\n        (dropout): Dropout(p=0.3, inplace=False)\n      )\n      (feature_fusion_layer): Feedforward(\n        (input_dropout): Dropout(p=0.4, inplace=False)\n        (hidden_dropout): Dropout(p=0.0, inplace=False)\n        (linear1): Linear(in_features=1600, out_features=400, bias=True)\n        (linear2): Linear(in_features=400, out_features=400, bias=True)\n      )\n      (field_table_fusion_layer): FusionLayer(\n        (res_dropout): Dropout(p=0.2, inplace=False)\n        (layer_dropout): Dropout(p=0.0, inplace=False)\n        (layer_norm): LayerNorm()\n        (res_feed_forward): ResidualBlock(\n          (mdl_with_residual_connection): ResidualConnectionWrapper(\n            (mdl): Feedforward(\n              (input_dropout): Dropout(p=0.4, inplace=False)\n              (hidden_dropout): Dropout(p=0.0, inplace=False)\n              (linear1): Linear(in_features=400, out_features=400, bias=True)\n              (linear2): Linear(in_features=400, out_features=400, bias=True)\n            )\n            (res_dropout): Dropout(p=0.2, inplace=False)\n            (layer_dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layer_norm): LayerNorm()\n        )\n      )\n    )\n  )\n  (decoder): BridgeDecoder(\n    (out): LogSoftmaxOutput(\n      (linear): Linear(in_features=400, out_features=99, bias=True)\n      (log_softmax): LogSoftmax(dim=-1)\n    )\n    (rnn): WeightDropoutLSTM(\n      (rnn): LSTM(800, 400, batch_first=True)\n    )\n    (attn): MultiHead(\n      (attention): AttentionDotProduct(\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (wq): Linear(in_features=400, out_features=400, bias=False)\n      (wk): Linear(in_features=400, out_features=400, bias=False)\n      (wv): Linear(in_features=400, out_features=400, bias=False)\n      (wo): Linear(in_features=400, out_features=400, bias=False)\n    )\n    (attn_combine): ConcatAndProject(\n      (input_dropout): Dropout(p=0.4, inplace=False)\n      (linear1): Linear(in_features=800, out_features=400, bias=True)\n    )\n    (pointer_switch): PointerSwitch(\n      (project): ConcatAndProject(\n        (input_dropout): Dropout(p=0.4, inplace=False)\n        (linear1): Linear(in_features=800, out_features=1, bias=True)\n      )\n    )\n  )\n)", "parameters": [["encoder_embeddings.trans_parameters.embeddings.word_embeddings.weight", [30522, 768]], ["encoder_embeddings.trans_parameters.embeddings.position_embeddings.weight", [512, 768]], ["encoder_embeddings.trans_parameters.embeddings.token_type_embeddings.weight", [2, 768]], ["encoder_embeddings.trans_parameters.embeddings.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.embeddings.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.attention.self.query.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.attention.self.query.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.attention.self.key.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.attention.self.key.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.attention.self.value.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.attention.self.value.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.attention.output.dense.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.attention.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.attention.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.attention.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.intermediate.dense.weight", [3072, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.intermediate.dense.bias", [3072]], ["encoder_embeddings.trans_parameters.encoder.layer.0.output.dense.weight", [768, 3072]], ["encoder_embeddings.trans_parameters.encoder.layer.0.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.0.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.attention.self.query.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.attention.self.query.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.attention.self.key.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.attention.self.key.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.attention.self.value.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.attention.self.value.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.attention.output.dense.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.attention.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.attention.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.attention.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.intermediate.dense.weight", [3072, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.intermediate.dense.bias", [3072]], ["encoder_embeddings.trans_parameters.encoder.layer.1.output.dense.weight", [768, 3072]], ["encoder_embeddings.trans_parameters.encoder.layer.1.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.1.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.attention.self.query.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.attention.self.query.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.attention.self.key.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.attention.self.key.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.attention.self.value.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.attention.self.value.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.attention.output.dense.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.attention.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.attention.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.attention.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.intermediate.dense.weight", [3072, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.intermediate.dense.bias", [3072]], ["encoder_embeddings.trans_parameters.encoder.layer.2.output.dense.weight", [768, 3072]], ["encoder_embeddings.trans_parameters.encoder.layer.2.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.2.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.attention.self.query.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.attention.self.query.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.attention.self.key.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.attention.self.key.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.attention.self.value.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.attention.self.value.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.attention.output.dense.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.attention.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.attention.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.attention.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.intermediate.dense.weight", [3072, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.intermediate.dense.bias", [3072]], ["encoder_embeddings.trans_parameters.encoder.layer.3.output.dense.weight", [768, 3072]], ["encoder_embeddings.trans_parameters.encoder.layer.3.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.3.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.attention.self.query.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.attention.self.query.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.attention.self.key.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.attention.self.key.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.attention.self.value.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.attention.self.value.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.attention.output.dense.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.attention.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.attention.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.attention.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.intermediate.dense.weight", [3072, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.intermediate.dense.bias", [3072]], ["encoder_embeddings.trans_parameters.encoder.layer.4.output.dense.weight", [768, 3072]], ["encoder_embeddings.trans_parameters.encoder.layer.4.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.4.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.attention.self.query.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.attention.self.query.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.attention.self.key.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.attention.self.key.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.attention.self.value.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.attention.self.value.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.attention.output.dense.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.attention.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.attention.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.attention.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.intermediate.dense.weight", [3072, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.intermediate.dense.bias", [3072]], ["encoder_embeddings.trans_parameters.encoder.layer.5.output.dense.weight", [768, 3072]], ["encoder_embeddings.trans_parameters.encoder.layer.5.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.5.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.attention.self.query.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.attention.self.query.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.attention.self.key.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.attention.self.key.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.attention.self.value.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.attention.self.value.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.attention.output.dense.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.attention.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.attention.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.attention.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.intermediate.dense.weight", [3072, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.intermediate.dense.bias", [3072]], ["encoder_embeddings.trans_parameters.encoder.layer.6.output.dense.weight", [768, 3072]], ["encoder_embeddings.trans_parameters.encoder.layer.6.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.6.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.attention.self.query.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.attention.self.query.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.attention.self.key.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.attention.self.key.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.attention.self.value.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.attention.self.value.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.attention.output.dense.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.attention.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.attention.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.attention.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.intermediate.dense.weight", [3072, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.intermediate.dense.bias", [3072]], ["encoder_embeddings.trans_parameters.encoder.layer.7.output.dense.weight", [768, 3072]], ["encoder_embeddings.trans_parameters.encoder.layer.7.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.7.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.attention.self.query.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.attention.self.query.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.attention.self.key.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.attention.self.key.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.attention.self.value.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.attention.self.value.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.attention.output.dense.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.attention.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.attention.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.attention.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.intermediate.dense.weight", [3072, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.intermediate.dense.bias", [3072]], ["encoder_embeddings.trans_parameters.encoder.layer.8.output.dense.weight", [768, 3072]], ["encoder_embeddings.trans_parameters.encoder.layer.8.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.8.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.attention.self.query.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.attention.self.query.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.attention.self.key.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.attention.self.key.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.attention.self.value.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.attention.self.value.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.attention.output.dense.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.attention.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.attention.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.attention.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.intermediate.dense.weight", [3072, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.intermediate.dense.bias", [3072]], ["encoder_embeddings.trans_parameters.encoder.layer.9.output.dense.weight", [768, 3072]], ["encoder_embeddings.trans_parameters.encoder.layer.9.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.9.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.attention.self.query.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.attention.self.query.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.attention.self.key.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.attention.self.key.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.attention.self.value.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.attention.self.value.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.attention.output.dense.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.attention.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.attention.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.attention.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.intermediate.dense.weight", [3072, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.intermediate.dense.bias", [3072]], ["encoder_embeddings.trans_parameters.encoder.layer.10.output.dense.weight", [768, 3072]], ["encoder_embeddings.trans_parameters.encoder.layer.10.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.10.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.attention.self.query.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.attention.self.query.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.attention.self.key.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.attention.self.key.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.attention.self.value.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.attention.self.value.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.attention.output.dense.weight", [768, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.attention.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.attention.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.attention.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.intermediate.dense.weight", [3072, 768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.intermediate.dense.bias", [3072]], ["encoder_embeddings.trans_parameters.encoder.layer.11.output.dense.weight", [768, 3072]], ["encoder_embeddings.trans_parameters.encoder.layer.11.output.dense.bias", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.output.LayerNorm.weight", [768]], ["encoder_embeddings.trans_parameters.encoder.layer.11.output.LayerNorm.bias", [768]], ["encoder_embeddings.trans_parameters.pooler.dense.weight", [768, 768]], ["encoder_embeddings.trans_parameters.pooler.dense.bias", [768]], ["decoder_embeddings.embeddings.weight", [99, 400]], ["encoder.bilstm_encoder.rnn.rnn.rnn.weight_ih_l0", [800, 768]], ["encoder.bilstm_encoder.rnn.rnn.rnn.weight_hh_l0", [800, 200]], ["encoder.bilstm_encoder.rnn.rnn.rnn.bias_ih_l0", [800]], ["encoder.bilstm_encoder.rnn.rnn.rnn.bias_hh_l0", [800]], ["encoder.bilstm_encoder.rnn.rnn.rnn.weight_ih_l0_reverse", [800, 768]], ["encoder.bilstm_encoder.rnn.rnn.rnn.weight_hh_l0_reverse", [800, 200]], ["encoder.bilstm_encoder.rnn.rnn.rnn.bias_ih_l0_reverse", [800]], ["encoder.bilstm_encoder.rnn.rnn.rnn.bias_hh_l0_reverse", [800]], ["encoder.text_encoder.rnn.rnn.rnn.weight_ih_l0", [800, 400]], ["encoder.text_encoder.rnn.rnn.rnn.weight_hh_l0", [800, 200]], ["encoder.text_encoder.rnn.rnn.rnn.bias_ih_l0", [800]], ["encoder.text_encoder.rnn.rnn.rnn.bias_hh_l0", [800]], ["encoder.text_encoder.rnn.rnn.rnn.weight_ih_l0_reverse", [800, 400]], ["encoder.text_encoder.rnn.rnn.rnn.weight_hh_l0_reverse", [800, 200]], ["encoder.text_encoder.rnn.rnn.rnn.bias_ih_l0_reverse", [800]], ["encoder.text_encoder.rnn.rnn.rnn.bias_hh_l0_reverse", [800]], ["encoder.schema_encoder.primary_key_embeddings.embeddings.weight", [2, 400]], ["encoder.schema_encoder.foreign_key_embeddings.embeddings.weight", [2, 400]], ["encoder.schema_encoder.field_type_embeddings.embeddings.weight", [6, 400]], ["encoder.schema_encoder.feature_fusion_layer.linear1.weight", [400, 1600]], ["encoder.schema_encoder.feature_fusion_layer.linear1.bias", [400]], ["encoder.schema_encoder.feature_fusion_layer.linear2.weight", [400, 400]], ["encoder.schema_encoder.feature_fusion_layer.linear2.bias", [400]], ["encoder.schema_encoder.field_table_fusion_layer.layer_norm.gamma", [400]], ["encoder.schema_encoder.field_table_fusion_layer.layer_norm.beta", [400]], ["encoder.schema_encoder.field_table_fusion_layer.res_feed_forward.mdl_with_residual_connection.mdl.linear1.weight", [400, 400]], ["encoder.schema_encoder.field_table_fusion_layer.res_feed_forward.mdl_with_residual_connection.mdl.linear1.bias", [400]], ["encoder.schema_encoder.field_table_fusion_layer.res_feed_forward.mdl_with_residual_connection.mdl.linear2.weight", [400, 400]], ["encoder.schema_encoder.field_table_fusion_layer.res_feed_forward.mdl_with_residual_connection.mdl.linear2.bias", [400]], ["encoder.schema_encoder.field_table_fusion_layer.res_feed_forward.layer_norm.gamma", [400]], ["encoder.schema_encoder.field_table_fusion_layer.res_feed_forward.layer_norm.beta", [400]], ["decoder.out.linear.weight", [99, 400]], ["decoder.out.linear.bias", [99]], ["decoder.rnn.rnn.weight_ih_l0", [1600, 800]], ["decoder.rnn.rnn.weight_hh_l0", [1600, 400]], ["decoder.rnn.rnn.bias_ih_l0", [1600]], ["decoder.rnn.rnn.bias_hh_l0", [1600]], ["decoder.attn.wq.weight", [400, 400]], ["decoder.attn.wk.weight", [400, 400]], ["decoder.attn.wv.weight", [400, 400]], ["decoder.attn.wo.weight", [400, 400]], ["decoder.attn_combine.linear1.weight", [400, 800]], ["decoder.attn_combine.linear1.bias", [400]], ["decoder.pointer_switch.project.linear1.weight", [1, 800]], ["decoder.pointer_switch.project.linear1.bias", [1]]], "output_shape": [[24, 50, 193]], "num_parameters": [23440896, 393216, 1536, 768, 768, 589824, 768, 589824, 768, 589824, 768, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 589824, 768, 589824, 768, 589824, 768, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 589824, 768, 589824, 768, 589824, 768, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 589824, 768, 589824, 768, 589824, 768, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 589824, 768, 589824, 768, 589824, 768, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 589824, 768, 589824, 768, 589824, 768, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 589824, 768, 589824, 768, 589824, 768, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 589824, 768, 589824, 768, 589824, 768, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 589824, 768, 589824, 768, 589824, 768, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 589824, 768, 589824, 768, 589824, 768, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 589824, 768, 589824, 768, 589824, 768, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 589824, 768, 589824, 768, 589824, 768, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 589824, 768, 39600, 614400, 160000, 800, 800, 614400, 160000, 800, 800, 320000, 160000, 800, 800, 320000, 160000, 800, 800, 800, 800, 2400, 640000, 400, 160000, 400, 400, 400, 160000, 400, 160000, 400, 400, 400, 39600, 99, 1280000, 640000, 1600, 1600, 160000, 160000, 160000, 160000, 320000, 400, 800, 1]}, {"name": "loss_fun", "id": 140399540496080, "class_name": "MaskedCrossEntropyLoss()", "parameters": [], "output_shape": [[]], "num_parameters": []}], "edges": []}